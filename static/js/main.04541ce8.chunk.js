(this.webpackJsonplodge=this.webpackJsonplodge||[]).push([[0],{10:function(e,t,s){},12:function(e,t,s){"use strict";s.r(t);var a=s(1),i=s.n(a),n=s(4),o=s.n(n),c=(s(10),s(5)),l=function(e,t){var s=document.getElementById(e);if(s){var a=s.getBoundingClientRect().top+window.pageYOffset+t;window.scrollTo({top:a,behavior:"auto"})}},r=s.p+"static/media/menu.36dfa9b1.svg",d=s.p+"static/media/github.04be58c1.svg",h=s.p+"static/media/Lodge_graphic_mono_color.b0914d10.svg",m=s(0);var g=function(){var e="hover:bg-gray-100 hover:border-gray-300 active:bg-green-200 active:border-green-300 border-l-4 border-white py-2.5 pl-4 text-left",t=Object(a.useState)(!1),s=Object(c.a)(t,2),i=s[0],n=s[1],o=function(e){l(e,-50),n(!1)};return Object(m.jsxs)("header",{children:[Object(m.jsxs)("div",{id:"header",className:"z-50 items-center bg-white fixed border-b border-gray-200 h-20 w-full flex justify-between",children:[Object(m.jsx)("a",{href:"/",children:Object(m.jsx)("img",{src:h,alt:"the Lodge logo",className:"h-20 ml-4"})}),Object(m.jsxs)("nav",{className:"hidden lg:flex bg-white h-full justify-between items-center text-center text-lg text-gray-500 font-medium",children:[Object(m.jsx)("button",{className:"mx-4",onClick:function(){return o("landing")},children:"Start Here"}),Object(m.jsx)("button",{className:"mx-4",onClick:function(){return o("case-study")},children:"Case Study"}),Object(m.jsx)("button",{className:"mx-4",onClick:function(){return o("presentation")},children:"Presentation"}),Object(m.jsx)("button",{className:"mx-4",onClick:function(){return o("our-team")},children:"Our Team"}),Object(m.jsx)("a",{href:"/lodge-docs",className:"mx-4",children:"Docs"}),Object(m.jsx)("a",{href:"https://github.com/lodge-logging/Lodge",className:"mx-4 w-20",children:Object(m.jsx)("img",{src:d,className:"w-full h-10",alt:"The github logo"})})]}),Object(m.jsx)("img",{src:r,alt:"a dropdown menu icon",className:"lg:hidden block w-8 h-8 mr-6",onClick:function(){return n(!i)}})]}),Object(m.jsxs)("div",{id:"mobile-menu",className:"lg:hidden ".concat(i?"translate-y-20":"-translate-y-full"," z-0 bg-white fixed flex flex-col text-xl text-gray-800 w-full gap-1 transform transition duration-500 ease-in-out"),children:[Object(m.jsx)("button",{onClick:function(){return o("landing")},className:"".concat(e," mt-1"),children:"Start Here"}),Object(m.jsx)("button",{onClick:function(){return o("case-study")},className:e,children:"Case Study"}),Object(m.jsx)("button",{onClick:function(){return o("presentation")},className:e,children:"Presentation"}),Object(m.jsx)("button",{onClick:function(){return o("our-team")},className:e,children:"Our Team"}),Object(m.jsx)("a",{href:"/lodge-docs",className:e,children:"Docs"}),Object(m.jsxs)("a",{href:"https://github.com/lodge-logging/Lodge",className:"".concat(e," mb-1"),children:[Object(m.jsx)("i",{className:""})," GitHub"]})]})]})},u=s.p+"static/media/Lodge_landing.d0cf1755.svg",b=s.p+"static/media/install-and-init.67f983b1.gif",j=s.p+"static/media/full_diagram.ab211138.png";var f=function(){return Object(m.jsxs)("div",{id:"landing",className:"text-white flex flex-col flex-nowrap",children:[Object(m.jsx)("div",{className:"flex flex-col justify-center items-center pt-28 bg-raisin xl:py-0",children:Object(m.jsxs)("div",{className:"w-full h-landing xl:h-screen xl:flex",children:[Object(m.jsx)("div",{className:"hidden xl:block bg-white bgImageFirst w-1/2"}),Object(m.jsx)("img",{className:"xl:hidden w-96 mx-auto mt-24",src:u,alt:" The Lodge logo"}),Object(m.jsxs)("div",{className:"xl:flex xl:flex-col xl:w-1/2 text-center items-center justify-center bg-raisin",children:[Object(m.jsx)("h1",{className:"hidden xl:block text-landing font-extrabold mt-32 -mb-6",children:"Lodge"}),Object(m.jsxs)("p",{className:"mt-10 xl:mt-0 light-text text-gray-300 text-3xl leading-snug text-center px-8 mx-auto max-w-xl",children:["An ",Object(m.jsx)("span",{className:"text-cyan font-medium",children:"open-source framework "})]}),Object(m.jsxs)("p",{className:"light-text text-gray-300 text-3xl leading-snug text-center px-8 mx-auto max-w-xl",children:["that provides",Object(m.jsx)("span",{className:"text-yellowgreen font-medium",children:" resilient observability "})]}),Object(m.jsx)("p",{className:"light-text text-gray-300 text-3xl leading-snug text-center px-8 mx-auto max-w-xl",children:"for distributed web applications"})]})]})}),Object(m.jsxs)("div",{className:"hidden xl:flex h-landing bgImageSecond justify-center items-center text-center bg-cyan py-20",children:[Object(m.jsx)("h2",{className:"text-4xl font-extrabold w-1/2",children:"Ready to Deploy"}),Object(m.jsxs)("div",{className:"flex flex-col w-1/2 justify-center mx-6 my-10 px-12",children:[Object(m.jsx)("p",{className:"mx-auto text-3xl mb-14 px-4",children:"Lodge provides an opinionated pre-configuration of open-source tools that deploy automatically to a user's AWS account"}),Object(m.jsx)("img",{src:b,alt:"Lodge initialization gif",className:"mx-auto rounded-lg shadow-xl"})]})]}),Object(m.jsxs)("div",{className:"xl:hidden flex flex-col h-landing-mobile justify-center items-center text-center bg-cyan py-20 px-4",children:[Object(m.jsx)("h2",{className:"text-4xl font-extrabold",children:"Ready to Deploy"}),Object(m.jsx)("p",{className:"text-3xl my-10 px-6 max-w-5xl",children:"Lodge provides an opinionated pre-configuration of open-source tools that deploy automatically to a user's AWS account"}),Object(m.jsx)("img",{src:b,alt:"Lodge initialization gif",className:"rounded-lg shadow-xl"})]}),Object(m.jsxs)("div",{className:"hidden xl:flex h-landing bgImageThird justify-center items-center text-center bg-yellowgreen py-20",children:[Object(m.jsx)("h2",{className:"text-4xl font-extrabold w-1/2",children:"Available and Resilient"}),Object(m.jsxs)("div",{className:"flex flex-col w-1/2 justify-center mx-6 my-10 px-4",children:[Object(m.jsxs)("p",{className:"mx-auto text-3xl mb-14 px-20",children:["Lodge is optimized for ",Object(m.jsx)("b",{children:"availability"})," in the event of datacenter outages, and ",Object(m.jsx)("b",{children:"resiliency"})," against sudden bursts in log traffic"]}),Object(m.jsx)("img",{src:j,alt:"Lodge diagram",className:"mx-auto rounded-lg shadow-xl"})]})]}),Object(m.jsxs)("div",{className:"xl:hidden flex flex-col h-landing-mobile justify-center items-center text-center bg-yellowgreen py-20 px-4",children:[Object(m.jsx)("h2",{className:"text-4xl font-extrabold",children:"Available and Resilient"}),Object(m.jsxs)("p",{className:"text-3xl my-10 px-6 max-w-5xl",children:["Lodge is optimized for ",Object(m.jsx)("b",{children:"availability"})," in the event of datacenter outages, and ",Object(m.jsx)("b",{children:"resiliency"})," against sudden bursts in log traffic"]}),Object(m.jsx)("img",{src:j,alt:"Lodge initialization gif",className:"rounded-lg shadow-xl"})]})]})};var p=function(){var e="my-4 hover:text-cyan",t="ml-8 my-4 hover:text-cyan",s="inline text-left text-raisin text-lg hover:text-black",a=function(e){return l(e,-100)};return Object(m.jsx)("aside",{id:"sideNav",className:"".concat("sticky xl:flex xl:self-start xl:w-1/5 xl:top-16 right-20 bg-white border-gray-100 border-r-2 p-4 pl-14 h-screen overflow-y-auto"," translate-x transform transition duration-700 hidden h-0"),children:Object(m.jsxs)("ul",{className:"list-outside list-disc text-yellowgreen text-3xl items-center",children:[Object(m.jsx)("li",{"data-section":"section-1",className:e,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-1")},children:"Lodge Introduction"})}),Object(m.jsx)("li",{"data-section":"section-2",className:e,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-2")},children:"Lodge Use Case"})}),Object(m.jsx)("li",{"data-section":"section-2",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-2-1")},children:"Boardwalk"})}),Object(m.jsx)("li",{"data-section":"section-2",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-2-2")},children:"Monolith to Microservices"})}),Object(m.jsx)("li",{"data-section":"section-2",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-2-3")},children:"Debugging Microservices"})}),Object(m.jsx)("li",{"data-section":"section-2",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-2-4")},children:"Observability"})}),Object(m.jsx)("li",{"data-section":"section-2",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-2-5")},children:"Time-Series Data"})}),Object(m.jsx)("li",{"data-section":"section-2",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-2-6")},children:"Bursty Traffic"})}),Object(m.jsx)("li",{"data-section":"section-2",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-2-7")},children:"Summary"})}),Object(m.jsx)("li",{"data-section":"section-3",className:e,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-3")},children:"Existing Solutions"})}),Object(m.jsx)("li",{"data-section":"section-3",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-3-1")},children:"Buying a Solution"})}),Object(m.jsx)("li",{"data-section":"section-3",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-3-2")},children:"Operating a Solution"})}),Object(m.jsx)("li",{"data-section":"section-3",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-3-3")},children:"Where Lodge Fits In"})}),Object(m.jsx)("li",{"data-section":"section-4",className:e,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-4")},children:"Lodge Architecture"})}),Object(m.jsx)("li",{"data-section":"section-4",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-4-1")},children:"Overview"})}),Object(m.jsx)("li",{"data-section":"section-4",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-4-2")},children:"Components"})}),Object(m.jsx)("li",{"data-section":"section-4",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-4-3")},children:"Filebeat for Collection and Shipping"})}),Object(m.jsx)("li",{"data-section":"section-4",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-4-4")},children:"Kafka for Buffering"})}),Object(m.jsx)("li",{"data-section":"section-4",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-4-5")},children:"Logstash for Parsing and Indexing"})}),Object(m.jsx)("li",{"data-section":"section-4",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-4-6")},children:"Elasticsearch and Amazon S3 for Storage"})}),Object(m.jsx)("li",{"data-section":"section-4",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-4-7")},children:"Kibana for Querying and Visualization"})}),Object(m.jsx)("li",{"data-section":"section-4",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-4-8")},children:"Lodge Dashboard for Everything Else"})}),Object(m.jsx)("li",{"data-section":"section-5",className:e,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-5")},children:"Using Lodge"})}),Object(m.jsx)("li",{"data-section":"section-5",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-5-1")},children:"Deploying Lodge"})}),Object(m.jsx)("li",{"data-section":"section-5",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-5-2")},children:"Viewing the Deployment"})}),Object(m.jsx)("li",{"data-section":"section-5",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-5-3")},children:"Shipping Logs"})}),Object(m.jsx)("li",{"data-section":"section-5",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-5-4")},children:"Viewing Logs"})}),Object(m.jsx)("li",{"data-section":"section-5",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-5-5")},children:"Re-Indexing Logs from S3 Archive"})}),Object(m.jsx)("li",{"data-section":"section-5",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-5-6")},children:"Managing Kafka Cluster"})}),Object(m.jsx)("li",{"data-section":"section-5",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-5-7")},children:"Component Review"})}),Object(m.jsx)("li",{"data-section":"section-6",className:e,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-6")},children:"Designing and Building Lodge"})}),Object(m.jsx)("li",{"data-section":"section-6",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-6-1")},children:"Kafka"})}),Object(m.jsx)("li",{"data-section":"section-6",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-6-2")},children:"Amazon S3"})}),Object(m.jsx)("li",{"data-section":"section-6",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-6-3")},children:"Bastion Host"})}),Object(m.jsx)("li",{"data-section":"section-7",className:e,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-7")},children:"Implementation Challenge"})}),Object(m.jsx)("li",{"data-section":"section-7",className:t,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-7-1")},children:"Resolving Circular Dependencies"})}),Object(m.jsx)("li",{"data-section":"section-8",className:e,children:Object(m.jsx)("button",{className:s,onClick:function(){return a("section-8")},children:"Future Work"})}),Object(m.jsx)("div",{className:"py-32"})]})})},x=s.p+"static/media/monolith.591c3c42.jpeg",w=s.p+"static/media/microservice.672503c4.jpeg",O=s.p+"static/media/fireGif.fc4816fa.gif",y=s.p+"static/media/monolith-ssh.488177d4.gif",N=s.p+"static/media/microservice-ssh.e5b8f69e.gif",v=s.p+"static/media/logsAggregated.efab7adf.png",k=s.p+"static/media/logsNormalized.7f2e788c.png",L=s.p+"static/media/timeseries.8fe470d1.gif",S=s.p+"static/media/bursty-logs.ecd7f5c6.gif",I=s.p+"static/media/buying-options.72dec619.png",T=s.p+"static/media/logging-solutions.031506a3.png",C=s.p+"static/media/elastic-stack.01d5e2e6.png",E=s.p+"static/media/overview.a27080dc.png",A=s.p+"static/media/components.57325461.png",K=s.p+"static/media/filebeat.7688093f.png",z=s.p+"static/media/kafka.9c7a879f.png",W=s.p+"static/media/logstash.40dbdf71.png",B=s.p+"static/media/s3.52edd1c2.png",D=s.p+"static/media/restore.f65a51ed.png",P=s.p+"static/media/kibana.e24af9c1.png",F=s.p+"static/media/dashboard.067d5c68.png",R=s.p+"static/media/lodge-aws-console.ec141448.gif",q=s.p+"static/media/logstash-no-broker.babb08c4.gif",H=s.p+"static/media/buffering-options.8c2fdae8.png",V=s.p+"static/media/kafka-logstash-in-action.2a3e0f21.gif",Z=s.p+"static/media/ES-cluster.f05d5b9e.png",M=s.p+"static/media/circular-dependencies.72b5b0a8.png",U=s.p+"static/media/dependency-stages.97aa310b.png",Q=s.p+"static/media/zookeeper-dependencies.e3d28dad.png",J=s.p+"static/media/component-review.a0d7019a.png";var _=function(){var e="text-3xl font-extrabold mt-14 mb-6",t="text-2xl font-bold mt-16 mb-4",s="text-xl font-bold mt-12 mb-4",a="my-5",i="inline text-raisin text-xl",n="ml-7",o="mx-auto my-8 rounded-lg",c="underline text-blue-500";return Object(m.jsxs)("div",{className:"flex",children:[Object(m.jsx)(p,{}),Object(m.jsx)("div",{id:"case-study",className:"xl:w-4/5 xl:pt-0",children:Object(m.jsxs)("div",{className:"prose ml-6 leading-9 w-10/12 text-left text-gray-700 text-xl",children:[Object(m.jsx)("h1",{className:"mt-24 mb-16 text-6xl font-black",children:"Case Study"}),Object(m.jsx)("h2",{id:"section-1",className:e,children:"1. Lodge Introduction"}),Object(m.jsx)("p",{className:a,children:"Lodge is an open source, self-managed logging framework for small, distributed applications. Lodge allows users to ship, transform, store, visualize, and monitor their logs."}),Object(m.jsx)("p",{className:a,children:"In this writeup, we\u2019re first going to give a brief narrative based on a fictitious company we\u2019ve invented for the purposes of outlining the ideal use case for Lodge. Then, we will conclude this narrative with a comparison of existing solutions to the problems it has introduced. Once we\u2019ve shown where Lodge fits in the context of the existing solutions, we will transition to an overview of Lodge\u2019s architecture followed by some demonstrations of how it works from a user\u2019s perspective. In the final sections, we will discuss some of the key design decisions we made as well as an implementation challenge we faced while building Lodge. Let\u2019s start things off with our use case."}),Object(m.jsx)("h2",{id:"section-2",className:e,children:"2. Lodge Use Case"}),Object(m.jsx)("h3",{id:"section-2-1",className:t,children:"2.1 Boardwalk"}),Object(m.jsx)("p",{className:a,children:"Boardwalk is a small, but fast-growing online retailer that sells handcrafted board games. Their product has become a huge hit on social media, which has exponentially increased the traffic on their website. This is an exciting time for Boardwalk, but also a challenging time, since their growth will require a complete overhaul of their architecture."}),Object(m.jsx)("p",{className:a,children:"Boardwalk\u2019s monolithic codebase has worked great up until now, but their increasing number of users are demanding an increasing number of new features, so their development pace needs to keep up, and their architecture needs to facilitate this new pace. This is why they\u2019ve decided to break up the monolith, and migrate to a microservice architecture."}),Object(m.jsx)("h3",{id:"section-2-2",className:t,children:"2.2 Monolith to Microservices"}),Object(m.jsx)("p",{className:a,children:"In a monolith architecture, the business logic of the application is run entirely on one machine. This means that different functional components, or modules, of the application can communicate by simply calling each other\u2019s methods."}),Object(m.jsx)("img",{src:x,alt:"monolith diagram",className:o}),Object(m.jsx)("p",{className:a,children:"For example, if a user wants to checkout their cart, they will trigger a request from the web server to the `/checkout` endpoint of the app server, which will then call the `checkInventory` method of the `inventory` module, which sends a SQL query to the database, and so on."}),Object(m.jsx)("p",{className:a,children:"A microservice architecture introduces network complexity between these modules:"}),Object(m.jsx)("img",{src:w,alt:"microservice diagram",className:o}),Object(m.jsx)("p",{className:a,children:"Services must now communicate by making API calls over an inherently unreliable network. The \u2018user checkout\u2019 event now begins with a request to the checkout service, which fetches the user\u2019s cart contents from its database, then initiates a request to the inventory service for it to verify that the product is available in its database, and so on. This complexity is not just added for fun, though. There are significant benefits gained from using this architecture."}),Object(m.jsx)("p",{className:a,children:"Remember, Boardwalk is aiming to increase development turnover on new features. So if they want to update their checkout service, they can do so independently of the rest of the services. And of course, Boardwalk is growing fast, so now they can accommodate this growth by horizontally scaling these services as needed."}),Object(m.jsx)("p",{className:a,children:"So now the Boardwalk team is set up to focus all their time and engineering effort on new features - right? Well, maybe not; there\u2019s a problem. Users are reporting issues with the checkout system. What does the team do?"}),Object(m.jsx)("h3",{id:"section-2-3",className:t,children:"2.3 Debugging microservices"}),Object(m.jsx)("p",{className:a,children:"In their previous architecture, the Boardwalk team needed only to SSH into their application server, and maybe their database server, to examine their application's logs."}),Object(m.jsx)("img",{src:y,alt:"SSHing into a monolith",className:o}),Object(m.jsx)("p",{className:a,children:"Now, they have to SSH into multiple instances, examine their logs, and try to piece together the entire application state from a series of isolated records."}),Object(m.jsx)("img",{src:N,alt:"SSHing into a microservice",className:o}),Object(m.jsx)("p",{className:a,children:"Is the checkout service running? Is the payment service running? Are they both running but the network is failing? Fortunately, the number of nodes is still low enough that it\u2019s possible, but as it increases, they can see that this process will soon become untenable."}),Object(m.jsx)("img",{src:O,alt:"A computer on fire",className:o}),Object(m.jsx)("p",{className:a,children:"So the team begins researching a solution. It\u2019s important to note here, however, that their users have not stopped using their application and the backlog of features these users have requested, including a more streamlined checkout service and a UI for customizing their board game orders, has not suddenly disappeared. They need a solution, but every minute they spend working on it is a minute they are not spending developing the application."}),Object(m.jsx)("h3",{id:"section-2-4",className:t,children:"2.4 Observability"}),Object(m.jsxs)("p",{className:a,children:["The team soon finds out that their problem has a name:"," ",Object(m.jsx)("b",{children:"observability"}),". The need for observability is universal across all distributed systems and the literature devoted to this subject is enormous. The type of observability solution that fits Boardwalk\u2019s use case is going to need to involve some sort of log aggregation. That is, they need to collect the logs from all the individual servers in their system and send them to one centralized location."]}),Object(m.jsx)("img",{src:v,alt:"Aggregated logs",className:o}),Object(m.jsx)("p",{className:a,children:"This process usually involves a collection agent that taps into the log files of whatever machine it is installed on, detects changes, and sends those changes over the network to another location. However, they also discover that since these log files contain raw text without much structure, just piling them all in a database as-is is not helpful. The logs need to be searchable."}),Object(m.jsx)("p",{className:a,children:"A mature observability solution needs to store the data in a way that it is queryable and visualizable. In SQL database terms, this process would entail dividing up the relevant characteristics of the logs, such as the timestamp, the source, and the message, and organizing the tables and columns of the database using these characteristics. That way, instead of visually scanning through thousands of lines of text, they can leverage all the power of SQL queries to find and analyze the logs they\u2019re looking for."}),Object(m.jsx)("img",{src:k,alt:"Aggregated, normalized logs",className:o}),Object(m.jsx)("p",{className:a,children:"In addition to being searchable, the data returned from these queries can now be fed into a visualization tool to create interactive dashboards. This is the path for getting from raw text stored in multiple locations to an interactive dashboard summarizing all of the data in one location. There is a bit more left to learn about logs, though, before the team can decide on a solution."}),Object(m.jsx)("h3",{id:"section-2-5",className:t,children:"2.5 Time-Series Data"}),Object(m.jsx)("p",{className:a,children:"One important factor they need to consider is the time-series nature of log data. This means the time the log occurred is a primary component in organizing it."}),Object(m.jsx)("div",{className:"h-72 overflow-hidden",children:Object(m.jsx)("img",{src:L,alt:"timeseries data",className:"mx-auto -mt-2"})}),Object(m.jsx)("p",{className:a,children:"If the team needs to diagnose a failure that occurs at 4:30pm, they need to see the logs generated in a narrow window of time leading up to and immediately after that time."}),Object(m.jsx)("p",{className:a,children:"Furthermore, time-series data has a shelf life. As it ages, it tends to become less and less relevant, so it\u2019s storage requirements evolve over time. The most recent logs need to be both written to and read from disk fast for real-time analysis. Whereas Tuesday\u2019s logs, for instance, will not need to be written to on Wednesday, and the likelihood that the team will need urgent access to logs from a year ago is next to none."}),Object(m.jsx)("h3",{id:"section-2-6",className:t,children:"2.6 Bursty Traffic"}),Object(m.jsx)("p",{className:a,children:"The other factor to consider is that logs are bursty."}),Object(m.jsxs)("div",{className:"flex mx-auto justify-center",children:[Object(m.jsx)("img",{src:S,alt:"a burst of logs",className:"-mr-3"}),Object(m.jsx)("div",{className:"bg-white w-4"})]}),Object(m.jsx)("p",{className:a,children:"While things are running well, logs tend to be generated in a fairly steady stream. However, when something goes wrong, systems can generate as much as 5 times the normal amount. If a logging solution is not prepared to handle those bursts, it can fail when it is needed most."}),Object(m.jsx)("h3",{id:"section-2-7",className:t,children:"2.7 Summary"}),Object(m.jsxs)("ul",{className:"list-outside list-disc text-gray-300 text-2xl items-center",children:[Object(m.jsx)("p",{className:i,children:"In summary, the team needs a solution that:"}),Object(m.jsx)("li",{className:n,children:Object(m.jsx)("p",{className:i,children:"Normalizes the logs"})}),Object(m.jsx)("li",{className:n,children:Object(m.jsx)("p",{className:i,children:"Collects the logs from all nodes"})}),Object(m.jsx)("li",{className:n,children:Object(m.jsx)("p",{className:i,children:"Stores the logs in a central location"})}),Object(m.jsx)("li",{className:n,children:Object(m.jsx)("p",{className:i,children:"Queries and visualizes the logs"})}),Object(m.jsx)("li",{className:n,children:Object(m.jsx)("p",{className:i,children:"Manages the storage of the logs based on relevance"})}),Object(m.jsx)("li",{className:n,children:Object(m.jsx)("p",{className:i,children:"Handles bursts of logs"})})]}),Object(m.jsx)("h2",{id:"section-3",className:e,children:"3. Existing Solutions"}),Object(m.jsx)("p",{className:a,children:"The team determines that their options are to buy, operate, or build a solution."}),Object(m.jsx)("h3",{id:"section-3-1",className:t,children:"3.1 Buying A Solution"}),Object(m.jsx)("p",{className:a,children:"Buying is the fastest and simplest option, but also the costliest."}),Object(m.jsx)("img",{src:I,alt:"the logos of existing solutions",className:"".concat(o," w-8/12")}),Object(m.jsxs)("p",{className:a,children:["There are great log management services in the marketplace such as"," ",Object(m.jsx)("a",{href:"https://logz.io/",className:c,children:"Logz"}),","," ",Object(m.jsx)("a",{href:"https://www.logdna.com/",className:c,children:"LogDNA"}),", and"," ",Object(m.jsx)("a",{href:"https://www.scalyr.com/",className:c,children:"Scalyr"}),". However, their convenience comes with a steep cost and the potentially sensitive data being sent to them is no longer owned by their users."]}),Object(m.jsxs)("p",{className:a,children:["AWS, like most cloud providers, does offer a"," ",Object(m.jsx)("a",{href:"https://docs.aws.amazon.com/cloudtrail/",className:c,children:"ready-to-deploy logging pipeline"})," ","consisting of managed services for ingesting, storing, and visualizing logs. This solution allows users to have the convenience of a managed solution while maintaining data ownership, but each component in the pipeline charges per log that passes through it, which, as log traffic increases, can potentially be even more expensive than the third-party managed solutions."]}),Object(m.jsx)("h3",{id:"section-3-2",className:t,children:"3.2 Operating A Solution"}),Object(m.jsx)("p",{className:a,children:"Operating entails installing an open source solution on their own infrastructure and maintaining it themselves."}),Object(m.jsxs)("p",{className:a,children:["There are multiple open source solutions available, but the one that is by far the most widely used is the ",Object(m.jsx)("b",{children:"Elastic stack"}),", formerly known as the ELK stack, which stands for Elasticsearch, Logstash, and Kibana."]}),Object(m.jsx)("img",{src:C,alt:"The elastic stack",className:o}),Object(m.jsx)("p",{className:a,children:"Logstash is used to transform and index the data into Elasticsearch, which is a document database whose shards contain instances of the full-text search engine called Apache Lucene. This design is in contrast to the SQL database paradigm we outlined before when discussing log aggregation in general. There are no tables for data to be normalized into. Instead, there are indexes, which Elastic recommends organizing by timestamp, not log source. That means that logs from all sources generated in a specified window time will be written to the same index. Then, once the specified time has elapsed, a new index will be created and no more logs will be written to the old one. No transformation is actually required to index the logs, since Elasticsearch stores text, but it does help the readability of the logs to do some formatting before they are stored."}),Object(m.jsx)("p",{className:a,children:"This data stored in Elasticsearch is then queried and visualized by Kibana, which uses Elasticsearch\u2019s REST API, rather than SQL. SQL-like query syntax is an available feature of Kibana, but the REST API is actually what\u2019s being used under the hood."}),Object(m.jsx)("p",{className:a,children:"Logstash, in addition to parsing and indexing data, is used to serve as a collection and shipping agent, but the Elastic team has since replaced it with their lighter weight tool Beats. The inclusion of Beats in the ELK stack is why Elastic now refers to it as the Elastic stack, which is the term we will use going forward."}),Object(m.jsx)("p",{className:a,children:"The Boardwalk team was able to easily install and use a small \u201cdevelopment mode\u201d stack for testing, but in researching the next steps required for production configuration, they found themselves in a deep and time-consuming territory of indexes, shards, JVM heap and garbage collection, multi-availability-zone clusters, grok patterns, and message queues."}),Object(m.jsx)("h3",{id:"section-3-3",className:t,children:"3.3 Where Lodge fits in"}),Object(m.jsx)("p",{className:a,children:"This configuration difficulty leaves the team with a dilemma: they don\u2019t have the budget to pay for the convenience of a managed solution, but they don\u2019t have the time to figure out how to set up a robust self-managed solution. In addition, they\u2019re not comfortable with giving up ownership of data for the convenience, either. If they could just get a viable Elastic stack deployed with a UI that makes the management sensible, they would be prepared to make the trade-off of the added time needed to manage the cluster for the ownership of data and the financial expense saved by not using a managed solution."}),Object(m.jsx)("p",{className:a,children:"This is where Lodge fits in."}),Object(m.jsx)("img",{src:T,alt:"solution comparison",className:"".concat(o," -mb-10")}),Object(m.jsx)("p",{className:a,children:"Lodge provides an opinionated pre-configuration for the Elastic stack that allows users to leverage Elastic\u2019s benefits while eliminating the engineering overhead of setting up the stack. Lodge does not eliminate the maintenance burden, but does provide a UI for facilitating stack maintenance. Furthermore, Lodge does use one managed service for log backup and archiving; but this actually both simplifies and even decreases storage cost for reasons we will get into later. Plus, users still get to own their data. The trade-off is that Lodge only provides pre-configuration for a small subset of log types, so users needing to ship other logtypes will not get as streamlined of an experience."}),Object(m.jsx)("p",{className:a,children:"So hopefully this hypothetical use case and existing solutions comparison has given you an understanding of why Lodge was built. Next, we\u2019d like to give a high-level overview of Lodge\u2019s architecture as well as some demos showing how Lodge works."}),Object(m.jsx)("h2",{id:"section-4",className:e,children:"4. Lodge Architecture"}),Object(m.jsx)("h3",{id:"section-4-1",className:t,children:"4.1 Overview"}),Object(m.jsx)("p",{className:a,children:"This is what Lodge looks like from a user\u2019s perspective on a high level."}),Object(m.jsx)("img",{src:E,alt:"An overview of Lodge",className:"".concat(o," max-w-xl -mb-8")}),Object(m.jsx)("p",{className:a,children:"The user has deployed Lodge on their network, so now all the applications in that network can ship logs to the stack using Filebeat, a subset of Beats specifically for collecting and forwarding log data. This user can then view those logs from the Lodge dashboard that is deployed with the stack."}),Object(m.jsx)("p",{className:a,children:"Next, let\u2019s zoom in on Lodge and take a closer look at its individual components."}),Object(m.jsx)("h3",{id:"section-4-2",className:t,children:"4.2 Components"}),Object(m.jsx)("p",{className:a,children:"Lodge\u2019s infrastructure consists of a series of components that work together to ship, transform, store, visualize, and monitor log data."}),Object(m.jsx)("img",{src:A,alt:"The components of Lodge",className:o}),Object(m.jsx)("p",{className:a,children:"Some of these components will be familiar from our previous discussion of the Elastic stack. Lodge uses these components as well as some additional supporting ones, all of which we will go over before we demonstrate how Lodge works."}),Object(m.jsx)("h3",{id:"section-4-3",className:t,children:"4.3 Filebeat for Collection and Shipping"}),Object(m.jsx)("p",{className:a,children:"First, we have Filebeat. This component is not actually part of the Lodge deployment, but it is the shipper that Lodge automatically generates configuration files for that the user installs on their servers."}),Object(m.jsx)("img",{src:K,alt:"Filebeat in the Lodge stack",className:o}),Object(m.jsx)("p",{className:a,children:"Filebeat is a lightweight shipper for forwarding and centralizing log data. Before Filebeat, Logstash was used both as a data collector as well as a data transformer. But there was one issue, Logstash required a Java Virtual Machine (JVM) to run. This dependency, combined with its implementation in Ruby, caused Logstash to consume far more memory than necessary just to perform the task of collecting and shipping logs. This overconsumption of memory is why Elastic created Beats. Beats decouples the tasks of collection and shipping from the parsing and indexing that Logstash does. Thanks to Beats, users can ship their logs without having to worry about their applications competing for resources with the collection agent."}),Object(m.jsx)("p",{className:a,children:"Once installed on the user\u2019s servers, Filebeat can actively monitor the log files specified in the configuration for changes and forward them to Kafka for ingestion into the Lodge pipeline."}),Object(m.jsx)("h3",{id:"section-4-4",className:t,children:"4.4 Kafka for Buffering"}),Object(m.jsx)("p",{className:a,children:"Next, we have Kafka. Kafka is the first supporting component we\u2019ve introduced. Logs and log volumes are unpredictable in nature. Following an incident in a production system, logs can suddenly surge and overwhelm an unprepared logging infrastructure precisely when it is needed most. In order to protect Logstash and Elasticsearch against such data bursts, Lodge has added Kafka to the Elastic stack as a buffering mechanism to flatten the curve when there is a sudden burst in log traffic"}),Object(m.jsx)("img",{src:z,alt:"Kafka in the Lodge stack",className:o}),Object(m.jsx)("p",{className:a,children:"Here, Kafka is deployed as a cluster. In order to manage the state of the Kafka cluster, we have Zookeeper deployed with it. We will discuss in more detail later in the design decisions section why we\u2019ve configured the cluster in this way, but for now just note that it\u2019s there to buffer incoming logs for Logstash."}),Object(m.jsx)("h3",{id:"section-4-5",className:t,children:"4.5 Logstash for Parsing and Indexing"}),Object(m.jsx)("p",{className:a,children:"After Kafka we have Logstash. To supplement what was mentioned before about Logstash, Logstash is a server-side real-time data-processing pipeline that ingests data from multiple sources simultaneously, transforms it, and then sends it to a \u201cstash\u201d like Elasticsearch and Amazon S3."}),Object(m.jsx)("img",{src:W,alt:"Logstash in the Lodge stack",className:o}),Object(m.jsx)("p",{className:a,children:"In this case, Logstash first ingests log data from specific Kafka topics, performs parsing and transformation, and sends logs to two different storage components in Lodge."}),Object(m.jsx)("h3",{id:"section-4-6",className:t,children:"4.6 Elasticsearch and Amazon S3 for Storage"}),Object(m.jsx)("p",{className:a,children:"This leads us to the storage layer. Here, in addition to Elasticsearch, we have an Amazon S3 bucket receiving data from Logstash."}),Object(m.jsx)("img",{src:B,alt:"S3 in the Lodge stack",className:o}),Object(m.jsx)("p",{className:a,children:"S3 is supporting Elasticsearch here by acting as a backup for data currently in Elasticsearch as well as long-term archive for data no longer needed in Elasticsearch. What exactly S3 is, and why we are using it instead of just storing data in Elasticsearch, we will also cover in the design decisions section."}),Object(m.jsx)("p",{className:a,children:"In between Elasticsearch and S3, we have Lodge Restore."}),Object(m.jsx)("img",{src:D,alt:"Lodge Restore in the Lodge stack",className:o}),Object(m.jsx)("p",{className:a,children:"As we mentioned previously, S3 stores data that is no longer needed in Elasticsearch. But what if the user changes their mind? For that purpose, we built an application to retrieve data from S3 and re-index it back into Elasticsearch."}),Object(m.jsx)("h3",{id:"section-4-7",className:t,children:"4.7 Kibana for Querying and Visualization"}),Object(m.jsx)("p",{className:a,children:"Kibana is the remaining Elastic stack component we use in Lodge. Kibana is Elastic\u2019s UI for interacting with Elasticsearch through its API. Kibana stores its data within Elasticsearch indices, so we can keep Kibana stateless."}),Object(m.jsx)("img",{src:P,alt:"kibana in the Lodge stack",className:o}),Object(m.jsx)("p",{className:a,children:"If the Kibana server goes down, users can simply spin up a new one without worrying about losing data - and this convenience comes without the hassle of managing a separate database."}),Object(m.jsx)("h3",{id:"section-4-8",className:t,children:"4.8 Lodge Dashboard for Everything Else"}),Object(m.jsx)("p",{className:a,children:"Finally, we have the Lodge Dashboard, which serves as a unified dashboard for using Kibana and Lodge Restore, downloading Filebeat configurations, and managing Kafka and Zookeeper clusters."}),Object(m.jsx)("img",{src:F,alt:"the Lodge dashboard in the Lodge stack",className:"".concat(o," max-w-xl")}),Object(m.jsx)("h2",{id:"section-5",className:e,children:"5. Using Lodge"}),Object(m.jsx)("h3",{id:"section-5-1",className:t,children:"5.1 Deploying Lodge"}),Object(m.jsxs)("ul",{className:"list-outside list-decimal text-2xl items-center",children:[Object(m.jsx)("li",{className:"".concat(n," pl-4"),children:Object(m.jsx)("p",{className:i,children:"The user installs the Lodge CLI."})}),Object(m.jsx)("li",{className:"".concat(n," pl-4"),children:Object(m.jsxs)("p",{className:i,children:["Once the installation is done, the user can run"," ",Object(m.jsx)("code",{children:"lodge init"})," to initialize Lodge and prepare it to be deployed on AWS."]})}),Object(m.jsx)("li",{className:"".concat(n," pl-4"),children:Object(m.jsxs)("p",{className:i,children:["Once the initialization is done, the user can run"," ",Object(m.jsx)("code",{children:"lodge deploy"}),", which after a few questions, it will deploy the entire Lodge infrastructure based on a series of Cloudformation templates that are generated from the Lodge CDK application, onto either a new AWS VPC or an existing VPC of their choice."]})}),Object(m.jsx)("li",{className:"".concat(n," pl-4"),children:Object(m.jsx)("p",{className:i,children:"As this is a large, complex deployment, it may take quite some time to finish."})})]}),Object(m.jsx)("h3",{id:"section-5-2",className:t,children:"5.2 Viewing the Deployment"}),Object(m.jsx)("p",{className:a,children:"Lodge is deployed on a total of 15 AWS EC2 instances that can be viewed and interacted with from the AWS console, if the user wishes to do so."}),Object(m.jsx)("img",{src:R,alt:"The aws console, showing Lodge deployed",className:o}),Object(m.jsx)("p",{className:a,children:"We can see in the AWS console that some of the components are deployed in multiple instances and in autoscaling groups with each instance in a different availability zone. The reasoning behind these design decisions, as well as the component we have not yet introduced, the bastion host, will be discussed in the next section. First, let\u2019s see what it looks like to use Lodge."}),Object(m.jsx)("h3",{id:"section-5-3",className:t,children:"5.3 Shipping Logs"}),Object(m.jsx)("p",{className:a,children:"In this sample deployment, we also included an instance running an Nginx web server that we named after our hypothetical use case, Boardwalk. In order to ship logs from this Boardwalk server to Lodge, we need to install Filebeat on it and verify that the configuration file included with the installation is located at `/etc/filebeat/filebeat.yml`. We need to remove this file `rm /etc/filebeat/filebeat.yml` and replace it with the configuration that we will generate from the Lodge Dashboard"}),Object(m.jsx)("p",{className:a,children:"In the Shippers section of the dashboard, we need to locate the Nginx module and click \u2018Download\u2019 to generate the Filebeat configuration. Then, we can create a Filebeat configuration file for our server `touch /etc/filebeat/filebeat.yml` and copy the contents of our generated configuration file to the new `filebeat.yml`. Finally, we need to apply the new configuration by restarting Filebeat `sudo systemctl restart filebeat.service`."}),Object(m.jsx)("p",{className:a,children:"To test that Nginx access logs are successfully being sent to Lodge, we can send a `curl` request to the server."}),Object(m.jsx)("h3",{id:"section-5-4",className:t,children:"5.4 Viewing Logs"}),Object(m.jsx)("p",{className:a,children:"To view the Nginx access log that we just generated, we can go to the Kibana tab in the Lodge Dashboard, and click on analytics within the embedded Kibana UI, and then Discover. Once in the Discover section, we can create an index pattern and view our logs."}),Object(m.jsx)("h3",{id:"section-5-5",className:t,children:"5.5 Re-Indexing Logs from S3 Archive"}),Object(m.jsx)("p",{className:a,children:"Another tool available in the Lodge Dashboard is Lodge Restore. Lodge Restore is a service that allows users to retrieve archived log data from Amazon S3 given a specific date range and to re-index the log data back into Elasticsearch to be visualized in Kibana. First, the user defines the start and end date to retrieve the archived logs from S3. Then, upon clicking \u2018Retrieve\u2019, all the log files that were inserted into S3 during that time frame will be fetched and listed for the user to review. Once the success message has been shown, it indicates that the logs are re-indexed into Elasticsearch behind the scenes and are ready to be visualized and queried in Kibana. We have also given the user the option to download the raw text of the individual log files, if needed."}),Object(m.jsx)("h3",{id:"section-5-6",className:t,children:"5.6 Managing Kafka Cluster"}),Object(m.jsx)("p",{className:a,children:"In the Lodge dashboard, we have integrated with two existing open source cluster management tools, Kafka Kowl and ZooNavigator. For users wanting more fine-grained control and visibility into one of the most complex parts of the Lodge infrastructure, these tools will be highly useful. Furthermore, users wishing to ship unsupported log types to Lodge will also appreciate these tools during the configuration process."}),Object(m.jsx)("h3",{id:"section-5-7",className:t,children:"5.7 Component Review"}),Object(m.jsx)("p",{className:a,children:"Here is a review of all the Lodge components: Filebeat for shipping logs to Lodge, Kafka for buffering the logs, Logstash for parsing, transforming, and indexing the logs, Elasticsearch and S3 for storing the logs, and the Lodge Dashboard for managing Kafka, re-indexing archived logs back into Elasticsearch from S3, and using Kibana, which is there to query and visualize the logs in Elasticsearch."}),Object(m.jsx)("img",{src:J,alt:"component overview",className:"".concat(o," max-w-4xl")}),Object(m.jsx)("h2",{id:"section-6",className:e,children:"6. Desigining and Building Lodge"}),Object(m.jsx)("p",{className:a,children:"In this final section, we are going to cover three design decisions we made and an implementation challenge we faced when building Lodge. The design decisions include adding Kafka, Amazon S3, and a bastion host. The implementation challenge is the resolution of circular dependencies during the automation of Lodge\u2019s deployment."}),Object(m.jsx)("p",{className:a,children:"Let\u2019s start with Kafka."}),Object(m.jsx)("h3",{id:"section-6-1",className:t,children:"6.1 Kafka"}),Object(m.jsx)("h4",{className:s,children:"Why a Buffer is Needed in the Elastic Stack"}),Object(m.jsx)("p",{className:a,children:"We\u2019ve already mentioned that logs are bursty in nature. That is, when something goes wrong, systems can all of a sudden generate a burst of logs much larger than the normal traffic it generates when everything is running smoothly. Logstash instances can only handle so much data and horizontal scaling doesn\u2019t happen instantly, so when this burst occurs, a large portion of the log data we would want can be lost, or worse, Logstash can crash and shut down the pipeline\u2019s ability to index any logs at all."}),Object(m.jsx)("img",{src:q,alt:"Logstash, overwhelmed",className:o}),Object(m.jsx)("p",{className:a,children:"A common solution for this problem is to use a data buffer so Logstash can pull log data off the end of the queue at its own pace, regardless of the rate at which the logs are generated."}),Object(m.jsx)("h4",{className:s,children:"Buffering Options"}),Object(m.jsxs)("p",{className:a,children:["There are"," ",Object(m.jsx)("a",{className:c,href:"https://www.logdna.com/blog/how-to-prevent-log-data-loss-when-using-elastic-search-in-a-production-environment",children:"three message queue options"})," ","that we considered for our pipeline:"]}),Object(m.jsx)("img",{src:H,alt:"A comparison of buffering options",className:"".concat(o," -ml-16")}),Object(m.jsx)("p",{className:a,children:"The first is RabbitMQ, which is a simple broker solution. However, when it has to enqueue large amounts of data, its responses to dequeue requests from Logstash slow down considerably. Redis is also an option, since it is an in-memory cache that can read and write enormous amounts of data at an incredible speed. Keeping data in memory allows it to be even faster than Kafka, but also makes it less reliable, since it does not persist data when it shuts down."}),Object(m.jsx)("h4",{className:s,children:"Choosing Kafka"}),Object(m.jsxs)("dl",{children:[Object(m.jsx)("p",{className:"mb-2",children:"We chose Kafka for its:"}),Object(m.jsxs)("div",{className:"flex mb-2",children:[Object(m.jsx)("dt",{className:"font-bold inline mr-12",children:"Durability:"}),Object(m.jsx)("dd",{className:"inline",children:"Kafka writes data to disk, so if a node crashes, data is not lost."})]}),Object(m.jsxs)("div",{className:"flex mb-2",children:[Object(m.jsx)("dt",{className:"font-bold inline mr-8",children:"Availability:"}),Object(m.jsx)("dd",{className:"inline",children:"Kafka replicates data across brokers, so if one broker goes down, its data is still accessible from the other brokers."})]}),Object(m.jsxs)("div",{className:"flex mb-2",children:[Object(m.jsx)("dt",{className:"font-bold inline mr-4",children:"Performance:"}),Object(m.jsx)("dd",{className:"inline",children:"Kafka is able to process a very high volume of messages very quickly, which makes it able to handle bursts in logs when they occur."})]})]}),Object(m.jsx)("img",{src:V,alt:"Kafka in action",className:"".concat(o," h-96")}),Object(m.jsx)("h3",{id:"section-6-2",className:t,children:"6.2 Amazon S3"}),Object(m.jsx)("p",{className:a,children:"The other supporting component we\u2019d like to discuss is S3. S3 is a file storage service managed by AWS. Before we talk more about S3, though, let\u2019s talk a little bit about Elasticsearch."}),Object(m.jsx)("h4",{className:s,children:"Storing Logs in Elasticsearch Only"}),Object(m.jsx)("p",{className:a,children:"Elasticsearch has an amazing built-in index lifecycle management system with tiered storage. Not only is there a dedicated data node role for reads and writes, but there are various specializations within the data role including search and machine learning optimized roles. The roles we considered using for our cluster were the roles specific to time-series data: hot, warm, cold, and frozen. The hot tier is where the most computing resources are needed, as this is where new logs are being written to the current index while also being read by Kibana for real-time analysis. Once new logs are no longer being written to an index, the index can be moved to the warm tier, where the data is still relevant enough that it still needs to be read fast, so it can be fully optimized for reads."}),Object(m.jsx)("p",{className:a,children:"As the tiers get \u2018colder\u2019, the indexes get smaller and slower to read, instead optimizing for storage. This system is great, and as much of a pleasure as it would have been to use it in our pipeline, it would have required deploying four times the servers we really needed for our use case. Furthermore, calculating the required SSD instance storage needed per node was not a decision we wanted to make for our users, as there are too many variables."}),Object(m.jsx)("h4",{className:s,children:"Adding S3"}),Object(m.jsx)("p",{className:a,children:"Instead, we opted to use S3 as both cold storage for older logs and as a backup for new logs. Even though S3 charges storage fees, storing logs as JSON-formatted text files in an S3 bucket is more space and cost efficient than storing them as JSON documents in Elasticsearch shards using local instance storage. The trade-off is speed. This trade-off is why we only want to keep the most recent logs in Elasticsearch, and move everything else to S3. If the user needs to see older logs, they will have to first re-index them into Elasticsearch from S3 using the Lodge-Restore tool in the dashboard. This design also provides a smaller and simpler starting architecture for their Elasticsearch cluster, which we will discuss in more detail next."}),Object(m.jsx)("h4",{className:s,children:"Lodge Elastic Cluster"}),Object(m.jsx)("p",{className:a,children:"Since we decided not to deploy the tiered data node architecture for Elasticsearch, we could start with only two generic data nodes and allow the user to scale from there. Otherwise, we were still able to follow Elastic\u2019s recommendations for designing an available and partition tolerant production cluster."}),Object(m.jsx)("img",{src:Z,alt:"The elasticsearch cluster",className:o}),Object(m.jsx)("p",{className:a,children:"Some of the specific recommendations we implemented were as follows:"}),Object(m.jsx)("p",{className:a,children:"Separating master-eligible and data node roles to dedicated instances so the tasks of managing cluster state and disk I/O operations do not compete for resources and they can scale independently."}),Object(m.jsx)("p",{className:a,children:"Scaling the data nodes horizontally with primary shards in one AZ and replicas in the other. We implemented this by deploying the data nodes in an autoscaling group across both AZs and configuring the cluster to allocate shards across the two AZs."}),Object(m.jsx)("p",{className:a,children:"Using a fixed odd number of master-eligible nodes (they recommend three) and scaling them vertically to keep up with the cluster state as it grows. With three master-eligible nodes, only one per AZ requires the resources to perform the master role in the event that it is elected. The third one can use minimal resources and only serve as a tie-breaker in the event of a partition between the AZs and a master election is held in both halves of the cluster. If this partition and subsequent master election occurs, the half of the cluster in the AZ with no vote-only node will not elect its master-eligible node as master, and instead, will go offline until a connection is established with the other half, which will remain online during the partition. This configuration allows half of the cluster to remain available, while preventing a split-brain scenario, where there are two nodes containing two different cluster states that both think they are the single source of truth for the cluster."}),Object(m.jsx)("p",{className:a,children:"With this architecture in place, users are able to choose how long they want to have immediate access to their logs from Kibana and delete the data from Elasticsearch once that time has elapsed. They can rest assured knowing that if they change their mind later, they can always re-index the data back into Elasticsearch for visualization with Kibana."}),Object(m.jsx)("h3",{id:"section-6-3",className:t,children:"6.3 Bastion Host"}),Object(m.jsx)("h4",{className:s,children:" Purpose of a Bastion Host "}),Object(m.jsx)("p",{className:a,children:"The one component we have not yet discussed is the bastion host. The purpose of a bastion host is to serve as a single point of ingress for administrators wanting to SSH into a network. If the network contains private (no ingress) subnets, then administrators wanting SSH access to the instances inside the private subnets will need an instance with a public IP in a public subnet to SSH into first, then connect to the private subnet instances from there. Without a bastion host, non web-facing application services and databases would need to be exposed to ingress from the internet in order to be maintained, which creates an unnecessary security vulnerability."}),Object(m.jsx)("h4",{className:s,children:" Lodge Bastion Host "}),Object(m.jsxs)("p",{className:a,children:["Lodge\u2019s architecture follows Kafka and Elasticsearch best practices by deploying them in private subnets. All Lodge components, including the internet-facing Kibana and Dashboard, only allow SSH access from the bastion host. Unlike a traditional bastion host, though, Lodge\u2019s does not allow SSH access to it. In fact, there are no open ports at all in Lodge\u2019s bastion host. Instead, Lodge uses AWS Systems Manager to authenticate user access with AWS credentials. This type of connection is called an SSM session, which users can initiate using the Lodge CLI. Once the SSM session has started in the bastion host, users can SSH into the Lodge components without needing to search for their IPs. For example, to SSH into one of the Kafka brokers from the bastion host, they would simply enter the command ",Object(m.jsx)("code",{children:"`/lodge-connect kafka1`"}),". More complete instructions for connecting to Lodge can be found in the documentation."]}),Object(m.jsx)("h2",{id:"section-7",className:e,children:"7. Implementation Challenges"}),Object(m.jsx)("p",{className:a,children:"In this final section, we\u2019re going to discuss a challenge we faced in resolving circular dependencies while automating Lodge\u2019s deployment."}),Object(m.jsx)("h3",{id:"section-7-1",className:t,children:"7.1 Resolving Circular Dependencies"}),Object(m.jsx)("h4",{className:s,children:"Relying on Values that Don't Exist Yet"}),Object(m.jsx)("p",{className:a,children:"For automating Lodge's deployment, we used AWS Cloud Development Kit, or CDK. CDK is AWS\u2019s infrastructure-as-code library that provides a dynamic interface for generating Cloudformation templates which our team preferred over working with Cloudformation directly."}),Object(m.jsx)("img",{src:M,alt:"circular dependencies",className:o}),Object(m.jsx)("p",{className:a,children:"In a CDK application, values that are used within the application, but are not actually known until after the infrastructure is deployed - values such as instance IDs or IP addresses - are assigned arbitrary tokens until their real values are resolved. However, if a component is dependent on the resolved token value of another component in the same stack, then its deployment will fail. For example, Logstash needs the IPs of the Kafka brokers as well as the Elasticsearch master-eligible nodes to network with them. If these IPs do not exist at the time Logstash\u2019s configuration file is generated, then we have a problem."}),Object(m.jsx)("h4",{className:s,children:"Resolving Values Before Using Them"}),Object(m.jsx)("p",{className:a,children:"The solution to this ordinary type of dependency, where one component is dependent on data from another, is simple: separate the components into their own deployment stage and deploy them in the order of their dependencies. For instance, Logstash can be deployed after Kafka and Elasticsearch, so their IPs are accessible when it\u2019s time for Logstash to deploy. We\u2019re confronted with a different type of dependency, though, with the components that are deployed in clusters."}),Object(m.jsx)("h4",{className:s,children:"Relying On Unresolved Values In Clusters"}),Object(m.jsx)("p",{className:a,children:"These components are Zookeeper and Elasticsearch. Kafka is also deployed in a cluster, but it uses Zookeeper\u2019s IPs to configure its cluster formation, so this dependency can be resolved like Logstash. Zookeeper and Elasticsearch, however, require their own IPs to form their clusters. For Zookeeper, that means every instance in the cluster needs its own IP as well as the IPs of the other two instances. So, in order for Zookeeper to deploy and form a cluster using its IPs, it needs AWS to assign the IPs, which can only happen after the instances have been deployed. This double-bind scenario is a circular dependency."}),Object(m.jsx)("img",{src:U,alt:"Dependency stages",className:"".concat(o," -my-10")}),Object(m.jsx)("p",{className:a,children:"Our options for resolving this circular dependency are either removing the dependency on IPs in the configuration or removing the dependency on AWS to generate and assign the IPs. With Elasticsearch, the former is possible, since the Elastic team has created a plugin specifically for AWS EC2 instances that replaces the need for user-input IPs with node names and fetches the IPs behind the scenes. Our Zookeeper solution requires the latter option."}),Object(m.jsx)("h4",{className:s,children:"Resolving Values Before Using Them: Zookeeper Edition"}),Object(m.jsx)("p",{className:a,children:"For Zookeeper, we need to determine the IPs ourselves before deployment. This means we first need to dynamically generate the IPs based on the CIDR block of the subnets that the cluster is deployed in. Where these CIDR blocks come from depends on how Lodge is deployed. For a new VPC, we create new subnets within the CIDR block provided by the user and calculate the first available IPs from there. The task is simpler than with an existing VPC, as we can assume that it is empty, other than the few IPs reserved by AWS."}),Object(m.jsx)("img",{src:Q,alt:"zookeeper depenencies",className:"".concat(o," -my-10")}),Object(m.jsx)("p",{className:a,children:"For an existing VPC, where the user selects the subnets they want to deploy Lodge in, we have to iterate through the range of IPs in a given CIDR block and verify that each potential IP is not already assigned, since we can no longer assume that the subnet is empty. We accomplish this verification using the AWS \u2018describe-network-interfaces\u2019 API, which can take an IP in the request and return a list of network interfaces attached to the IP in the response. If an IP has a network interface attached to it, that means the IP is in use. Using these approaches, once we find the IPs we need for Zookeeper, we can assign them to the instances directly and insert them into their configuration before they deploy."}),Object(m.jsx)("h2",{id:"section-8",className:e,children:"8. Future Work"}),Object(m.jsx)("p",{className:"".concat(a," mb-24"),children:"There\u2019s still more work we have left to do on Lodge to make it suitable for more use cases and relieve more of the user\u2019s management burden. We\u2019d like to start by adding support for more log types. Then, we\u2019d like to add monitoring and alerts for Lodge and implement intelligent autoscaling for Elasticsearch. Finally, we\u2019d like to make Lodge deployable on any cloud environment."})]})})]})};var G=function(){return Object(m.jsx)("div",{id:"presentation",className:"flex flex-col",children:Object(m.jsxs)("div",{className:"bg-gray-200 flex flex-col text-center px-36 py-20 h-video",children:[Object(m.jsx)("h2",{className:"text-6xl text-gray-800 mb-12 font-extrabold",children:"Presentation"}),Object(m.jsx)("iframe",{className:"rounded-lg border-2 border-gray-700 shadow-lg mx-auto h-full w-full",src:"https://www.youtube.com/embed/HToQQsURZWo",title:"YouTube video player",frameBorder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"})]})})},Y=s(3),X=s.p+"static/media/regina.67a24091.png",$=s.p+"static/media/justin.9741c09a.png",ee=s.p+"static/media/sam.ffd0ea1b.png",te=s.p+"static/media/rana.117f7d71.png",se=s.p+"static/media/email.21f403d1.svg",ae=s.p+"static/media/website.da1ff378.svg",ie=s.p+"static/media/github.2624d8dd.svg",ne=s.p+"static/media/linkedin.36e3c5fe.svg";var oe=function(e){var t=e.image,s=e.name,a=e.location,i=e.email,n=e.linkedin,o=e.github,c=e.website;return Object(m.jsxs)("li",{className:"flex flex-col bg-gray-800 rounded-xl py-9 px-4 text-center",children:[Object(m.jsx)("img",{className:"mx-auto h-48 w-48 rounded-full xl:w-56 xl:h-56 lazy",src:t,alt:""}),Object(m.jsxs)("div",{children:[Object(m.jsxs)("div",{children:[Object(m.jsx)("h3",{className:"text-white mt-9",children:s}),Object(m.jsx)("p",{className:"text-green-300 my-3",children:a})]}),Object(m.jsxs)("ul",{className:"bg-white-100 mx-auto mt-6 flex w-48 justify-between items-center",children:[Object(m.jsx)("li",{children:Object(m.jsx)("a",{href:i,children:Object(m.jsx)("img",{className:"w-8",src:se,alt:"email icon"})})}),Object(m.jsx)("li",{children:Object(m.jsx)("a",{href:n,children:Object(m.jsx)("img",{className:"w-6",src:ne,alt:"linkedin icon"})})}),Object(m.jsx)("li",{children:Object(m.jsx)("a",{href:o,children:Object(m.jsx)("img",{className:"w-8",src:ie,alt:"github icon"})})}),Object(m.jsx)("li",{children:Object(m.jsx)("a",{href:c,children:Object(m.jsx)("img",{className:"w-8",src:ae,alt:"website icon"})})})]})]})]})},ce=[{image:X,name:"Regina Donovan",location:"Atlanta, GA",email:"reginadonovan191@gmail.com",linkedin:"https://www.linkedin.com/in/rg-donovan/",github:"https://github.com/rgdonovan",website:""},{image:$,name:"Justin Lo",location:"Vancouver, BC",email:"justinkevinhl@gmail.com",linkedin:"https://www.linkedin.com/in/justinkevinheilo/",github:"https://github.com/justinnnlo",website:""},{image:ee,name:"Sam Clark",location:"Dallas, TX",email:"clarksam19@gmail.com",linkedin:"https://www.linkedin.com/in/sam-clark-dev",github:"https://github.com/clarksam19",website:"https://samclark.dev/"},{image:te,name:"Rana Deeb",location:"San Francisco, CA",email:"ranadeeb92@gmail.com",linkedin:"www.linkedin.com/in/rana-deeb/",github:"github.com/ranadeeb92",website:"www.ranadeeb.dev"}];var le=function(){return Object(m.jsx)("div",{id:"our-team",className:"flex flex-col px-4 bg-gray-900 text-gray-300 text-2xl",children:Object(m.jsxs)("div",{className:"px-4 py-16 max-w-7xl xl:max-w-none xl:w-11/12 mx-auto",children:[Object(m.jsxs)("div",{className:"",children:[Object(m.jsx)("h2",{className:"font-extrabold text-white text-5xl leading-9",children:"Meet our team"}),Object(m.jsx)("p",{className:"mt-8 w-8/12",children:"We are currently looking for opportunities. If you liked what you saw and want to talk more, please reach out!"})]}),Object(m.jsx)("ul",{className:"mt-14 flex flex-col gap-4 md:flex-row md:grid md:grid-cols-2 xl:grid-cols-4 md:gap-x-8 md:gap-y-12",children:ce.map((function(e,t){return Object(a.createElement)(oe,Object(Y.a)(Object(Y.a)({},e),{},{key:t}))}))})]})})};var re=function(){return Object(m.jsxs)("div",{className:"App",children:[Object(m.jsx)(g,{}),Object(m.jsx)(f,{}),Object(m.jsx)(_,{}),Object(m.jsx)(G,{}),Object(m.jsx)(le,{})]})};o.a.render(Object(m.jsx)(i.a.StrictMode,{children:Object(m.jsx)(re,{})}),document.getElementById("root"))}},[[12,1,2]]]);
//# sourceMappingURL=main.04541ce8.chunk.js.map